{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfa43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa3dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Villes françaises avec coordonnées\n",
    "cities = ['Paris', 'Marseille', 'Lyon', 'Toulouse', 'Nice', 'Nantes', 'Montpellier', \n",
    " 'Strasbourg', 'Bordeaux', 'Lille', 'Rennes', 'Reims', 'Saint-Étienne', \n",
    " 'Le Havre', 'Toulon', 'Grenoble', 'Dijon', 'Angers', 'Nîmes', 'Villeurbanne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d3c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à Snowflake\n",
    "load_dotenv(r'D:\\DATA\\2025-11-28_MSPR-1_2\\Good-Air\\.env')\n",
    "\n",
    "ACOUNT_SNOWFLAKE = os.getenv('ACOUNT_SNOWFLAKE')\n",
    "USER_SNOWFLAKE = os.getenv('USER_SNOWFLAKE')\n",
    "PASSWORD_SNOWFLAKE = os.getenv('PASSWORD_SNOWFLAKE')\n",
    "conn = snowflake.connector.connect(\n",
    "    user=USER_SNOWFLAKE,\n",
    "    password=PASSWORD_SNOWFLAKE,\n",
    "    account=ACOUNT_SNOWFLAKE,  # ex: \"abcd-xy12345.europe-west4.gcp\"\n",
    "    warehouse=\"COMPUTE_WH\",\n",
    "    database=\"GOOD_AIR\",\n",
    "    schema=\"BRONZE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046e0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune date de mise a jours récente\n"
     ]
    }
   ],
   "source": [
    "#récupération de la derniére date de mise à jours de la table hubeau_clean\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT LAST_ALTERED\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_NAME = 'BRONZE' \n",
    "      AND TABLE_SCHEMA = 'HUBEAU_SCRAP'\n",
    "\"\"\")\n",
    "\n",
    "result = cur.fetchone()\n",
    "last_date_maj = \"\"\n",
    "\n",
    "try :\n",
    "    last_date_maj = result[0]\n",
    "    last_date_maj = last_date_maj.replace(tzinfo=None)\n",
    "    print(f\" ************************* date snowflake récupéré {last_date_maj}\")\n",
    "except :\n",
    "     print('Aucune date de mise a jours récente')\n",
    "\n",
    "#A supp lors du déploiement\n",
    "if not last_date_maj :\n",
    "    last_date_maj = datetime.strptime(\"2020-09-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccc881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dis-2025.zip\n",
      "Mis à jour le 3 novembre 2025 zip (202,3 Mo)\n",
      "4K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "date maj : 2025-11-03 00:00:00\n",
      "dis-2025-dept.zip\n",
      "Mis à jour le 3 novembre 2025 zip (202,5 Mo)\n",
      "2K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "dis-2024.zip\n",
      "Mis à jour le 28 mars 2025 zip (274,4 Mo)\n",
      "1K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "date maj : 2025-03-28 00:00:00\n",
      "dis-2024-dept.zip\n",
      "Mis à jour le 29 mars 2025 zip (274,6 Mo)\n",
      "2K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "dis-2023.zip\n",
      "Mis à jour le 14 octobre 2024 zip (278,4 Mo)\n",
      "2K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "date maj : 2024-10-14 00:00:00\n",
      "dis-2023-dept.zip\n",
      "Mis à jour le 14 octobre 2024 zip (278,5 Mo)\n",
      "3K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "dis-2022-dept.zip\n",
      "Mis à jour le 7 juillet 2023 zip (293,9 Mo)\n",
      "909\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "dis-2022.zip\n",
      "Mis à jour le 7 juillet 2023 zip (293,7 Mo)\n",
      "1K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "date maj : 2023-07-07 00:00:00\n",
      "dis-2021-dept.zip\n",
      "Mis à jour le 11 août 2023 zip (292,4 Mo)\n",
      "1K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n",
      "dis-2021.zip\n",
      "Mis à jour le 11 août 2023 zip (292,2 Mo)\n",
      "1K\n",
      "TÉLÉCHARGER LA LISTE AU FORMAT\n",
      "ZIP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '11/août/2023' does not match format '%d/%B/%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     date_maj \u001b[38;5;241m=\u001b[39m dis\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m     28\u001b[0m     date_maj \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(date_maj)\n\u001b[1;32m---> 29\u001b[0m     date_maj \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_maj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate maj :\u001b[39m\u001b[38;5;124m'\u001b[39m, date_maj)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\_strptime.py:555\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    553\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 555\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    557\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\_strptime.py:333\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    331\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    334\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    337\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data '11/août/2023' does not match format '%d/%B/%Y'"
     ]
    }
   ],
   "source": [
    "#récupérer la liste des documents a téléchager\n",
    "\n",
    "# Lancer le navigateur \n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Ouvre l'URL de ta page\n",
    "driver.get(\"https://www.data.gouv.fr/datasets/resultats-du-controle-sanitaire-de-leau-distribuee-commune-par-commune/\")\n",
    "\n",
    "# Laisser un peu de temps pour charger la page\n",
    "time.sleep(3)\n",
    "\n",
    "# Récupérer tous les éléments avec la classe \"space-y-2.5\"\n",
    "elements = driver.find_elements(By.CSS_SELECTOR, \"div.border.border-gray-default.overflow-auto\")\n",
    "\n",
    "list_dis =[]\n",
    "\n",
    "# Définir la locale en français\n",
    "locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')\n",
    "\n",
    "# Afficher leur texte\n",
    "for  el in elements:\n",
    "\n",
    "    print(el.text)\n",
    "    dis = el.text\n",
    "    if \"dept\" not in dis and \".pdf\" not in dis :\n",
    "        #extrait les dates de mis a jour des balise et les convertis en datetime\n",
    "        date_maj = dis.split(\"\\n\")[1].split(\" \")[4:7]\n",
    "        date_maj =\"/\".join(date_maj)\n",
    "        date_maj = datetime.strptime(date_maj, \"%d/%B/%Y\")\n",
    "        print('date maj :', date_maj)\n",
    "\n",
    "    dis = el.text\n",
    "    if \"dept\" not in dis and \".pdf\" not in dis :\n",
    "        #extrait les dates de mis a jour des balise et les convertis en datetime\n",
    "        date_maj = dis.split(\"\\n\")[1].split(\" \")[4:7]\n",
    "        date_maj =\"/\".join(date_maj)\n",
    "        \n",
    "        if \"û\" in date_maj :\n",
    "            date_maj = date_maj.replace(\"û\",\"Ã»\")\n",
    "\n",
    "        date_maj = datetime.strptime(date_maj, \"%d/%B/%Y\")\n",
    "\n",
    "        #vérifie si la date du document à scrapper et plus récente que celle en bdd\n",
    "        if date_maj > last_date_maj :\n",
    "            print(dis.split(\"\\n\")[0], \" \" ,date_maj)\n",
    "\n",
    "            try:\n",
    "                # trouver le bouton <a> à l'intérieur de la div\n",
    "                button = el.find_element(By.CSS_SELECTOR, \"a.matomo_download\")\n",
    "                \n",
    "                # Option 1 : cliquer directement\n",
    "                button.click()\n",
    "                time.sleep(2)  # petit délai pour le téléchargement\n",
    "\n",
    "                time.sleep(300)\n",
    "                driver.quit()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Élément : pas de bouton ou erreur - {e}\")\n",
    "        else :\n",
    "            print(\"Dataset déjà à jour\")\n",
    "            driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05b59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:10: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:10: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:10: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  zip_path = f\"{download_path}\\{doc}\"\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\516815102.py:19: DtypeWarning: Columns (0,1,2,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "# chemin vers le dossier download\n",
    "download_path = r\"C:\\Users\\Utilisateur\\Downloads\"\n",
    "\n",
    "list_donwload = os.listdir(download_path)\n",
    "list_df = []\n",
    "\n",
    "for doc in list_donwload :\n",
    "    if \"dis-\" in doc : \n",
    "        \n",
    "        zip_path = f\"{download_path}\\{doc}\"\n",
    "        \n",
    "        # ouvrir le ZIP\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # liste des fichiers contenus dans le ZIP\n",
    "            for file_name in zip_ref.namelist():\n",
    "                    if \"PLV\" in file_name :\n",
    "                        with zip_ref.open(file_name) as f:\n",
    "                            # adapte le séparateur selon ton fichier (',' ou '\\t' ou ';')\n",
    "                            df = pd.read_csv(f, sep=\",\")\n",
    "                            list_df.append(df)\n",
    "\n",
    "df_concat = pd.concat(list_df)\n",
    "\n",
    "# Dictionnaire de renommage\n",
    "rename_dict = {\n",
    "    'dateprel' : 'date_plv',\n",
    "    'nomcommuneprinc': 'city_name',\n",
    "    'plvconformitereferencebact': 'conformite_ref_bact',\n",
    "    'plvconformitereferencechim' : 'conformite_ref_chim',\n",
    "    'plvconformitebacterio' : 'conformite_bact',\n",
    "    'plvconformitechimique' : 'conformite_chim',\n",
    "    'conclusionprel' :'conclusion_plv',\n",
    "}\n",
    "\n",
    "# Renommer les colonnes\n",
    "df_concat = df_concat.rename(columns=rename_dict)\n",
    "\n",
    "#reduire le dict au colonne désiré /renomé\n",
    "df = df_concat[list(rename_dict.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b917b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\1062825867.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"city_name\"] = df[\"city_name\"].apply(clean_cities)\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\1062825867.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"city_name\"] = df[\"city_name\"].apply(corel_city)\n",
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\1062825867.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduce[\"city_name\"] = df_reduce[\"city_name\"].str.upper()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_plv</th>\n",
       "      <th>city_name</th>\n",
       "      <th>conformite_ref_bact</th>\n",
       "      <th>conformite_ref_chim</th>\n",
       "      <th>conformite_bact</th>\n",
       "      <th>conformite_chim</th>\n",
       "      <th>conclusion_plv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>NICE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>NICE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>NICE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>NICE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170469</th>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>TOULON</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170470</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>TOULOUSE</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau conforme aux limites de qualité réglementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170471</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>TOULOUSE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170472</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>TOULOUSE</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170473</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>TOULOUSE</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Eau d'alimentation conforme aux exigences de q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170474 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_plv city_name conformite_ref_bact conformite_ref_chim  \\\n",
       "0       2021-07-22     PARIS                   C                   C   \n",
       "1       2021-01-04      NICE                   C                   C   \n",
       "2       2021-01-18      NICE                   C                   C   \n",
       "3       2021-02-01      NICE                   C                   C   \n",
       "4       2021-02-15      NICE                   C                   C   \n",
       "...            ...       ...                 ...                 ...   \n",
       "170469  2025-07-29    TOULON                   C                   C   \n",
       "170470  2025-03-25  TOULOUSE                   N                   C   \n",
       "170471  2025-04-01  TOULOUSE                   C                   C   \n",
       "170472  2025-03-25  TOULOUSE                   S                   C   \n",
       "170473  2025-07-10  TOULOUSE                   C                   C   \n",
       "\n",
       "       conformite_bact conformite_chim  \\\n",
       "0                    C               C   \n",
       "1                    C               C   \n",
       "2                    C               C   \n",
       "3                    C               C   \n",
       "4                    C               C   \n",
       "...                ...             ...   \n",
       "170469               C               C   \n",
       "170470               C               C   \n",
       "170471               C               C   \n",
       "170472               S               C   \n",
       "170473               C               C   \n",
       "\n",
       "                                           conclusion_plv  \n",
       "0       Eau d'alimentation conforme aux exigences de q...  \n",
       "1       Eau d'alimentation conforme aux exigences de q...  \n",
       "2       Eau d'alimentation conforme aux exigences de q...  \n",
       "3       Eau d'alimentation conforme aux exigences de q...  \n",
       "4       Eau d'alimentation conforme aux exigences de q...  \n",
       "...                                                   ...  \n",
       "170469  Eau d'alimentation conforme aux exigences de q...  \n",
       "170470  Eau conforme aux limites de qualité réglementa...  \n",
       "170471  Eau d'alimentation conforme aux exigences de q...  \n",
       "170472  Eau d'alimentation conforme aux exigences de q...  \n",
       "170473  Eau d'alimentation conforme aux exigences de q...  \n",
       "\n",
       "[170474 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean city_name\n",
    "def clean_cities(city) :\n",
    "    if city == 'NIMES' :\n",
    "         return 'NÎMES'\n",
    "    if city == 'SAINT-ETIENNE' :\n",
    "         return 'SAINT-ÉTIENNE'\n",
    "    if city == 'HAVRE (LE)' :\n",
    "         return 'LE HAVRE'\n",
    "    else :\n",
    "         return city\n",
    "\n",
    "def corel_city(row_city)   :\n",
    "     for city in cities :\n",
    "          if row_city.lower() in city.lower() :\n",
    "               return city\n",
    "          \n",
    "\n",
    "df[\"city_name\"] = df[\"city_name\"].apply(clean_cities)\n",
    "df[\"city_name\"] = df[\"city_name\"].apply(corel_city)\n",
    "\n",
    "# Filtrer le DataFrame\n",
    "df_reduce = df[df[\"city_name\"].isin(cities)]\n",
    "df_reduce[\"city_name\"] = df_reduce[\"city_name\"].str.upper()\n",
    "df_reduce.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb08de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer les nom de colonne en majusucle pour Snowflake \n",
    "df_reduce.columns = [c.upper() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5f11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_16824\\1026264495.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_dim_city = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 20 lignes.\n"
     ]
    }
   ],
   "source": [
    "#récupérer les id des city depuis snowflake\n",
    "query  = \"\"\" SELECT CITY_NAME, CITY_ID FROM GOOD_AIR.SILVER.DIM_CITY \"\"\"\n",
    "\n",
    "try:\n",
    "    df_dim_city = pd.read_sql(query, conn)\n",
    "    print(f\"Données chargées : {df_dim_city.shape[0]} lignes.\")\n",
    "finally:\n",
    "    conn.close() # Toujours fermer la connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d994f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_reduce, df_dim_city, how =\"left\", on=\"CITY_NAME\") \n",
    "df_merge.drop(columns= [\"CITY_NAME\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c07c697d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE_PLV', 'CONFORMITE_REF_BACT', 'CONFORMITE_REF_CHIM',\n",
       "       'CONFORMITE_BACT', 'CONFORMITE_CHIM', 'CONCLUSION_PLV', 'CITY_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90fb8b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDependencyError",
     "evalue": "Missing optional dependency: pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDependencyError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Charger le DataFrame vers une table (la table doit exister)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m success, nchunks, nrows, _ \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_merge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFACT_HUBEAU_RECORDS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload terminé : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lignes insérées.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\DATA\\2025-11-28_MSPR-1_2\\Good-Air\\venv\\Lib\\site-packages\\snowflake\\connector\\pandas_tools.py:392\u001b[0m, in \u001b[0;36mwrite_pandas\u001b[1;34m(conn, df, table_name, database, schema, chunk_size, compression, on_error, parallel, quote_identifiers, infer_schema, auto_create_table, create_temp_table, overwrite, table_type, use_logical_type, iceberg_config, bulk_upload_chunks, use_vectorized_scanner, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex, \u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRangeIndex\u001b[49m)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mstep\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mstart\n\u001b[0;32m    395\u001b[0m ):\n\u001b[0;32m    396\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas Dataframe has non-standard index of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which will not be written.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider changing the index to pd.RangeIndex(start=0,...,step=1) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    402\u001b[0m     )\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# use_logical_type should be True when dataframe contains datetimes with timezone.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# https://github.com/snowflakedb/snowflake-connector-python/issues/1687\u001b[39;00m\n",
      "File \u001b[1;32md:\\DATA\\2025-11-28_MSPR-1_2\\Good-Air\\venv\\Lib\\site-packages\\snowflake\\connector\\options.py:36\u001b[0m, in \u001b[0;36mMissingOptionalDependency.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mMissingDependencyError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dep_name)\n",
      "\u001b[1;31mMissingDependencyError\u001b[0m: Missing optional dependency: pandas"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger le DataFrame vers une table (la table doit exister)\n",
    "success, nchunks, nrows, _ = write_pandas(conn, df_merge, \"FACT_HUBEAU_RECORDS\")\n",
    "\n",
    "print(f\"Upload terminé : {success}, {nrows} lignes insérées.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
